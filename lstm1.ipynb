{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD3qfJG0sYU5",
        "outputId": "547ad69b-e669-417f-a17e-322ac4bf7081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "# for preprocessing \n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "#for model training\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "# from sklearn.cross_validation import KFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dirname, _, filenames in os.walk('./kaggle/input/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "OAAK7SRMslFP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR = './kaggle/input/'\n",
        "TrainX = pd.read_csv('training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\n",
        "Trainy = TrainX['domain1_score']\n",
        "TrainX = TrainX.dropna(axis=1)\n",
        "TrainX = TrainX.drop(columns=['rater1_domain1', 'rater2_domain1'])\n",
        "TrainX.head()\n",
        "# print(Trainy)\n",
        "\n",
        "TestX = pd.read_csv(os.path.join('test_set.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
        "Testy = TestX['domain1_predictionid']\n",
        "TestX = TestX.dropna(axis=1)\n",
        "# TestX = TestX.drop(columns=['rater1_domain1', 'rater2_domain1'])\n",
        "TestX.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XiyTavozsolF",
        "outputId": "706b8cd3-6529-4636-c97c-594b6b869b57"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0      2383          1  I believe that computers have a positive effec...   \n",
              "1      2384          1  Dear @CAPS1, I know some problems have came up...   \n",
              "2      2385          1  Dear to whom it @MONTH1 concern, Computers are...   \n",
              "3      2386          1  Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...   \n",
              "4      2387          1  Dear Local newspaper, I think that people have...   \n",
              "\n",
              "   domain1_predictionid  \n",
              "0                  2383  \n",
              "1                  2384  \n",
              "2                  2385  \n",
              "3                  2386  \n",
              "4                  2387  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72494167-8459-4a60-860f-4777ad6464d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2383</td>\n",
              "      <td>1</td>\n",
              "      <td>I believe that computers have a positive effec...</td>\n",
              "      <td>2383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2384</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1, I know some problems have came up...</td>\n",
              "      <td>2384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2385</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear to whom it @MONTH1 concern, Computers are...</td>\n",
              "      <td>2385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2386</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...</td>\n",
              "      <td>2386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2387</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local newspaper, I think that people have...</td>\n",
              "      <td>2387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72494167-8459-4a60-860f-4777ad6464d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72494167-8459-4a60-860f-4777ad6464d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72494167-8459-4a60-860f-4777ad6464d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing Data\n",
        "# Helper functions used to clean the essays\n",
        "\n",
        "extra_words = ['us','whose', 'ORGANIZATION', 'PEOPLE', 'LOCATION', 'DATE', 'CAPS',\n",
        "                   'NUM', 'MONTH', 'YEAR', 'PERCENT', 'TIME', 'MONEY', 'QUANTITY', 'LANGUAGE']\n",
        "\n",
        "def essayToWords(essay, remove, extras):\n",
        "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
        "    # chars removed\n",
        "    # |([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\"\n",
        "    essay = re.sub(\"[^a-zA-Z]\", \" \", essay)\n",
        "    words = essay.lower().split()\n",
        "    # stop words removed\n",
        "    if remove:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    # extra words removed\n",
        "        words = [w for w in words if not w in extra_words]\n",
        "    return (words)\n",
        "\n",
        "\n",
        "def essayToSentences(essay, remove, extras):\n",
        "    \"\"\"Tokenize the essay into sentences and call essayToWords() for word tokenization.\"\"\"\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(essay.strip())\n",
        "    sentences = []\n",
        "    for sente in raw_sentences:\n",
        "        if len(sente) > 0:\n",
        "            sentences.append(essayToWords(sente, remove, extras))\n",
        "    return sentences\n",
        "\n",
        "# visualising\n",
        "print(TrainX['essay'][0])\n",
        "print('Words', essayToWords(TrainX['essay'][0], True, extra_words ))\n",
        "print('Sentences', essayToSentences(TrainX['essay'][0], True, extra_words ))\n"
      ],
      "metadata": {
        "id": "0c2Y-Jj2svzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a45763-18e0-444d-993f-8298b86a395f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\n",
            "Words ['dear', 'local', 'newspaper', 'think', 'effects', 'computers', 'people', 'great', 'learning', 'skills', 'affects', 'give', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'learn', 'globe', 'astronomy', 'keeps', 'troble', 'thing', 'dont', 'think', 'would', 'feel', 'teenager', 'always', 'phone', 'friends', 'ever', 'time', 'chat', 'friends', 'buisness', 'partner', 'things', 'well', 'new', 'way', 'chat', 'computer', 'plenty', 'sites', 'internet', 'organization', 'organization', 'caps', 'facebook', 'myspace', 'ect', 'think', 'setting', 'meeting', 'boss', 'computer', 'teenager', 'fun', 'phone', 'rushing', 'get', 'cause', 'want', 'use', 'learn', 'countrys', 'states', 'outside', 'well', 'computer', 'internet', 'new', 'way', 'learn', 'going', 'time', 'might', 'think', 'child', 'spends', 'lot', 'time', 'computer', 'ask', 'question', 'economy', 'sea', 'floor', 'spreading', 'even', 'date', 'surprise', 'much', 'knows', 'believe', 'computer', 'much', 'interesting', 'class', 'day', 'reading', 'books', 'child', 'home', 'computer', 'local', 'library', 'better', 'friends', 'fresh', 'perpressured', 'something', 'know', 'isnt', 'right', 'might', 'know', 'child', 'caps', 'forbidde', 'hospital', 'bed', 'drive', 'rather', 'child', 'computer', 'learning', 'chatting', 'playing', 'games', 'safe', 'sound', 'home', 'community', 'place', 'hope', 'reached', 'point', 'understand', 'agree', 'computers', 'great', 'effects', 'child', 'gives', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'learn', 'globe', 'believe', 'keeps', 'troble', 'thank', 'listening']\n",
            "Sentences [['dear', 'local', 'newspaper', 'think', 'effects', 'computers', 'people', 'great', 'learning', 'skills', 'affects', 'give', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'learn', 'globe', 'astronomy', 'keeps', 'troble'], ['thing'], ['dont', 'think'], ['would', 'feel', 'teenager', 'always', 'phone', 'friends'], ['ever', 'time', 'chat', 'friends', 'buisness', 'partner', 'things'], ['well', 'new', 'way', 'chat', 'computer', 'plenty', 'sites', 'internet', 'organization', 'organization', 'caps', 'facebook', 'myspace', 'ect'], ['think', 'setting', 'meeting', 'boss', 'computer', 'teenager', 'fun', 'phone', 'rushing', 'get', 'cause', 'want', 'use'], ['learn', 'countrys', 'states', 'outside'], ['well', 'computer', 'internet', 'new', 'way', 'learn', 'going', 'time'], ['might', 'think', 'child', 'spends', 'lot', 'time', 'computer', 'ask', 'question', 'economy', 'sea', 'floor', 'spreading', 'even', 'date', 'surprise', 'much', 'knows'], ['believe', 'computer', 'much', 'interesting', 'class', 'day', 'reading', 'books'], ['child', 'home', 'computer', 'local', 'library', 'better', 'friends', 'fresh', 'perpressured', 'something', 'know', 'isnt', 'right'], ['might', 'know', 'child', 'caps', 'forbidde', 'hospital', 'bed', 'drive'], ['rather', 'child', 'computer', 'learning', 'chatting', 'playing', 'games', 'safe', 'sound', 'home', 'community', 'place'], ['hope', 'reached', 'point', 'understand', 'agree', 'computers', 'great', 'effects', 'child', 'gives', 'time', 'chat', 'friends', 'new', 'people', 'helps', 'learn', 'globe', 'believe', 'keeps', 'troble'], ['thank', 'listening']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Get feature vectors\n",
        "# def getFeatureVect(words, model, num_features):\n",
        "#     \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
        "#     featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "#     num_words = 0.\n",
        "#     index2word_set = set(model.wv.index2word)\n",
        "#     for word in words:\n",
        "#         if word in index2word_set:\n",
        "#             num_words += 1\n",
        "#             featureVec = np.add(featureVec,model[word])        \n",
        "#     featureVec = np.divide(featureVec,num_words)\n",
        "#     return featureVec\n",
        "\n",
        "# def getAvgFeatureVecs(essays, model, num_features):\n",
        "#     \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
        "#     counter = 0\n",
        "#     essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "#     for essay in essays:\n",
        "#         essayFeatureVecs[counter] = getFeatureVect(essay, model, num_features)\n",
        "#         counter = counter + 1\n",
        "#     return essayFeatureVecs"
      ],
      "metadata": {
        "id": "qlASKIyIN-6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "def get_model():\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "BT9zbt__s2eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings\n",
        "batch_size = 16\n",
        "epochs = 15\n",
        "learningRate = 1e-3\n",
        "num_features = 300 "
      ],
      "metadata": {
        "id": "fjvGenZ46E-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training - In Works\n",
        "epoch_num = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  train_essays = TrainX['essay']\n",
        "  test_essays = TestX['essay']\n",
        "  epoch_num.append(epoch)\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "\n",
        "  sentences = []\n",
        "\n",
        "  for essay in train_essays:\n",
        "    # Obtaining all sentences from the training essays.\n",
        "    sentences += essayToSentences(essay, remove_stopwords = True)"
      ],
      "metadata": {
        "id": "TAIRHmhl5-kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "# cv = KFold(n_splits = 5, shuffle = True)\n",
        "# for traincv, testcv in cv.split(X):\n",
        "\n",
        "#   print(traincv)\n",
        "#   print(testcv)\n",
        "#just indexes of splits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNlbmXg_zoqo",
        "outputId": "ec168544-0cda-4ada-da94-0644372ef0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    0     1     2 ... 12973 12974 12975]\n",
            "[    7     8    13 ... 12956 12958 12960]\n"
          ]
        }
      ]
    }
  ]
}