{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aljBqW5wP_T_",
        "CmedEn4CLiAx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### importing"
      ],
      "metadata": {
        "id": "E60ibzW4PYk-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0qoVnlFz8NbJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import  LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import string\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install language-tool-python\n",
        "!apt update\n",
        "!apt install enchant --fix-missing\n",
        "!apt install -qq enchant\n",
        "!pip install pyenchant\n",
        "import language_tool_python\n",
        "import enchant\n",
        "tknzr = TweetTokenizer()\n",
        "d = enchant.Dict(\"en_US\")\n"
      ],
      "metadata": {
        "id": "MPTwvBMr9Rjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set  = pd.read_csv('training_set.csv', encoding = \"ISO-8859-1\")\\\n",
        "            .rename(columns={ 'essay_set': 'topic','domain1_score': 'target_score', 'domain2_score': 'topic2_target'})\n",
        "training_set.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "umFxFTve8T1U",
        "outputId": "8295aee4-c2bf-4d9f-e42d-09348db19e8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  topic                                              essay  \\\n",
              "5         6      1  Dear @LOCATION1, I think that computers have a...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  target_score  \n",
              "5               4               4             8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7e4287a-c369-4ebd-8462-0a1d6acac85b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>target_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I think that computers have a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7e4287a-c369-4ebd-8462-0a1d6acac85b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7e4287a-c369-4ebd-8462-0a1d6acac85b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7e4287a-c369-4ebd-8462-0a1d6acac85b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### feature extraction funcs"
      ],
      "metadata": {
        "id": "aljBqW5wP_T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(filename):\n",
        "    dataset = pd.read_table(filename, header=0, sep=\",\", encoding=\"unicode_escape\")\n",
        "    \n",
        "    essay_set1 = dataset.loc[dataset['essay_set'] == 1]\n",
        "    essay_set3 = dataset.loc[dataset['essay_set'] == 3]\n",
        "    essay_set4 = dataset.loc[dataset['essay_set'] == 4]\n",
        "    essay_set5 = dataset.loc[dataset['essay_set'] == 5]\n",
        "    essay_set6 = dataset.loc[dataset['essay_set'] == 6]\n",
        "    essay_set7 = dataset.loc[dataset['essay_set'] == 7]\n",
        "    return ([ essay_set1['essay'], essay_set3['essay'], essay_set4['essay'], essay_set5['essay'], essay_set6['essay'], essay_set7['essay'] ])\n",
        "\n",
        "def word_tokenization(es):\n",
        "\n",
        "    # for essay in essay_set:\n",
        "    proper_pronouns = ['@ORGANIZATION', '@PEOPLE', '@LOCATION', '@DATE', '@CAPS', '@NUM', '@MONTH', '@YEAR', '@PERCENT', '@TIME', '@MONEY', '@QUANTITY', '@LANGUAGE']\n",
        "    e_tokenize = tknzr.tokenize(es)\n",
        "    bag_of_words = []\n",
        "    for x in e_tokenize:\n",
        "        if (x[:len(x)-1] in proper_pronouns) or (x in string.punctuation):\n",
        "            pass\n",
        "        else:\n",
        "            bag_of_words.append(x.lower())\n",
        "\n",
        "    # print(bag_of_words)\n",
        "\n",
        "    # word-based tokenization\n",
        "    word_tokens = {}\n",
        "    token = 1\n",
        "    for x in bag_of_words:\n",
        "        if x in word_tokens.keys():\n",
        "            pass\n",
        "        else:\n",
        "            word_tokens[x] = token\n",
        "            token += 1\n",
        "\n",
        "    return word_tokens\n",
        "    \n",
        "def vocabulary_check(word_tokens):\n",
        "\n",
        "    # check for vocabulary errors\n",
        "    total_words = len(word_tokens)\n",
        "    correctness = 0\n",
        "    correct = 0\n",
        "    for x in word_tokens.keys():\n",
        "        if (d.check(x) == True):\n",
        "            correct = correct + 1\n",
        "\n",
        "    misspelt = total_words - correct \n",
        "    return misspelt\n",
        "\n",
        "def extract_feature_set4():\n",
        "    words_count = []\n",
        "    word_count = 0\n",
        "    sentences_count = []\n",
        "    unique_words_count = []\n",
        "\n",
        "    essaysets = load_file(\"training_set.csv\")\n",
        "    for essayset in essaysets:\n",
        "        for essay in essayset:\n",
        "            length = len(essay.split())\n",
        "            words_count.append(length)\n",
        "\n",
        "            total_sentences = 0\n",
        "            sentences = essay.split('.')\n",
        "            for i in sentences:\n",
        "                sentences[total_sentences] = sentences[total_sentences].split()\n",
        "                total_sentences = total_sentences + 1\n",
        "            sentences_count.append(total_sentences)\n",
        "\n",
        "            \n",
        "            unique_words = []\n",
        "            for word in essay.split():\n",
        "                if word not in unique_words:\n",
        "                    unique_words.append(word)\n",
        "\n",
        "            unique_words_count.append(len(unique_words))\n",
        "\n",
        "    return(words_count, sentences_count, unique_words_count)\n",
        "\n",
        "def extract_feature_set2(word_tokens):\n",
        "    \n",
        "    # EMOTIVE EFFECTIVENESS FEATURE SET\n",
        "    lexicon = {}\n",
        "    with open('subjclueslen1-HLTEMNLP05.tff') as f:\n",
        "        \n",
        "        for line in f:\n",
        "            content = f.readline()\n",
        "            row = content.split()\n",
        "            type = row[0][5:]\n",
        "            words = row[2][6:]\n",
        "            pos = row[3][5:]\n",
        "            polarity = row[5][14:]\n",
        "            \n",
        "            lexicon[words] = (type, pos, polarity)\n",
        "\n",
        "    # print(lexicon)\n",
        "\n",
        "    strong_positive = 0\n",
        "    strong_negative = 0\n",
        "    strong_neutral = 0\n",
        "    strong_both = 0\n",
        "\n",
        "    weak_positive = 0\n",
        "    weak_negative = 0\n",
        "    weak_neutral = 0\n",
        "    weak_both = 0\n",
        "\n",
        "    for w in word_tokens.keys():\n",
        "        if w in lexicon.keys():\n",
        "            if lexicon[w][0] == \"strongsubj\":\n",
        "                if lexicon[w][2] == \"positive\":\n",
        "                    strong_positive += 1\n",
        "\n",
        "                elif lexicon[w][2] == \"negative\":\n",
        "                    strong_negative += 1\n",
        "\n",
        "                elif lexicon[w][2] == \"neutral\":\n",
        "                    strong_neutral += 1\n",
        "\n",
        "                elif lexicon[w][2] == \"both\":\n",
        "                    strong_both += 1 \n",
        "\n",
        "            elif lexicon[w][0] == \"weaksubj\":\n",
        "                if lexicon[w][2] == \"positive\":\n",
        "                    weak_positive += 1\n",
        "\n",
        "                elif lexicon[w][2] == \"negative\":\n",
        "                    weak_negative += 1\n",
        "\n",
        "                elif lexicon[w][2] == \"neutral\":\n",
        "                    weak_neutral += 1\n",
        "\n",
        "                elif lexicon[w][2] == \"both\":\n",
        "                    weak_both += 1 \n",
        "    \n",
        "    return strong_positive/len(word_tokens), strong_negative/len(word_tokens), strong_neutral/len(word_tokens), strong_both/len(word_tokens), weak_positive/len(word_tokens), weak_negative/len(word_tokens), weak_neutral/len(word_tokens), weak_both/len(word_tokens)"
      ],
      "metadata": {
        "id": "c0krcsuAQFqz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### feature extraction"
      ],
      "metadata": {
        "id": "bICQRL5ePdzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "# MISTAKES and MISSPELT WORDS\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "misspeltarr = []\n",
        "training_set['matches'] = training_set['essay'].apply(lambda txt: tool.check(txt))\n",
        "training_set['corrections'] = training_set.apply(lambda l: len(l['matches']), axis=1)\n",
        "training_set['corrected'] = training_set['essay'].apply(lambda txt: tool.correct(txt))\n",
        "\n",
        "essaysets = load_file(\"training_set.csv\" )\n",
        "for essayset in essaysets:\n",
        "  for essay in essayset:\n",
        "\n",
        "    word_tokens = word_tokenization(essay)\n",
        "    misspelt =  vocabulary_check(word_tokens)\n",
        "    misspeltarr.append(misspelt)\n",
        "\n",
        "\n",
        "training_set[\"misspelt\"] = misspeltarr\n"
      ],
      "metadata": {
        "id": "ce5eaUkD8kvz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "# LANGUAGE FLUENCY AND DEXTERITY\n",
        "### word count, unique word count, sentence count\n",
        "\n",
        "word_count, sentence_count, unique_word_count  = extract_feature_set4()\n",
        "training_set[\"word_count\"] = word_count\n",
        "training_set[\"sentence_count\"] = sentence_count\n",
        "training_set[\"unique_word_count\"] = unique_word_count"
      ],
      "metadata": {
        "id": "VX9y27El5Mr9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "# PARTS OF SPEECH\n",
        "# nouns, adjectives, verbs and pronouns\n",
        "\n",
        "pos = []\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "np.warnings.filterwarnings('ignore')\n",
        "for essay in nlp.pipe(training_set['corrected'], batch_size=100):\n",
        "    if essay.is_parsed:\n",
        "        pos.append([e.pos_ for e in essay])\n",
        "    else:\n",
        "        pos.append(None)\n",
        "\n",
        "\n",
        "training_set['pos'] = pos\n",
        "training_set['noun'] = training_set.apply(lambda x: x['pos'].count('NOUN'), axis=1)\n",
        "training_set['adj'] = training_set.apply(lambda x: x['pos'].count('ADJ'), axis=1)\n",
        "training_set['pron'] = training_set.apply(lambda x: x['pos'].count('PRON'), axis=1)\n",
        "training_set['verb'] = training_set.apply(lambda x: x['pos'].count('VERB'), axis=1)\n"
      ],
      "metadata": {
        "id": "xSxBZj1tAmyr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "# SUBJECTIVE - EMOTIVE EFFECTIVENESS FEATURE SET\n",
        "sp = []\n",
        "sneg = []\n",
        "sneut = []\n",
        "sb = []\n",
        "wp = []\n",
        "wneg = []\n",
        "wneu = []\n",
        "wb = []\n",
        "\n",
        "essaysets = load_file(\"training_set.csv\" )\n",
        "for essayset in essaysets:\n",
        "  for essay in essayset:\n",
        "\n",
        "    word_tokens = word_tokenization(essay)\n",
        "    strong_positive, strong_negative, strong_neutral, strong_both, weak_positive, weak_negative, weak_neutral, weak_both = extract_feature_set2(word_tokens)\n",
        "\n",
        "    sp.append(strong_positive)\n",
        "    sneg.append(strong_negative)\n",
        "    sneut.append(strong_neutral)\n",
        "    sb.append(strong_both)\n",
        "    wp.append(weak_positive)\n",
        "    wneg.append(weak_negative)\n",
        "    wneu.append(weak_neutral)\n",
        "    wb.append(weak_both)\n",
        "training_set[\"strong_positive\"] = sp\n",
        "training_set[\"strong_negative\"] = sneg\n",
        "training_set[\"strong_neutral\"] = sneut\n",
        "training_set[\"strong_both\"] = sb\n",
        "training_set[\"weak_positive\"] = wp\n",
        "training_set[\"weak_negative\"] = wneg\n",
        "training_set[\"weak_neutral\"] = wneu\n",
        "training_set[\"weak_both\"] = wb"
      ],
      "metadata": {
        "id": "L4azJJkePNZS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features = ['corrections', 'misspelt', 'word_count', 'sentence_count', 'unique_word_count', 'noun', 'adj','pron','verb', 'strong_positive', 'strong_negative', 'strong_neutral', 'strong_both', 'weak_positive', 'weak_negative', 'weak_neutral', 'weak_both']"
      ],
      "metadata": {
        "id": "-4LsIZF2BiVS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "IwiAT8rBUUCa",
        "outputId": "fea813bb-958d-453d-b226-a1c8892765fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     essay_id  topic                                              essay  \\\n",
              "221       222      5  The author generally stayed in one mood. The m...   \n",
              "\n",
              "     rater1_domain1  rater2_domain1  target_score  \\\n",
              "221               3               3             3   \n",
              "\n",
              "                                               matches  corrections  \\\n",
              "221  [Offset 114, length 4, Rule ID: COMMA_COMPOUND...            9   \n",
              "\n",
              "                                             corrected  misspelt  ...  pron  \\\n",
              "221  The author generally stayed in one mood. The m...         3  ...    23   \n",
              "\n",
              "     verb  strong_positive strong_negative  strong_neutral  strong_both  \\\n",
              "221    18         0.034483        0.011494             0.0          0.0   \n",
              "\n",
              "     weak_positive  weak_negative  weak_neutral  weak_both  \n",
              "221       0.045977       0.011494      0.022989        0.0  \n",
              "\n",
              "[1 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11776dc0-d168-466e-942b-6befd2b3d37e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>topic</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>target_score</th>\n",
              "      <th>matches</th>\n",
              "      <th>corrections</th>\n",
              "      <th>corrected</th>\n",
              "      <th>misspelt</th>\n",
              "      <th>...</th>\n",
              "      <th>pron</th>\n",
              "      <th>verb</th>\n",
              "      <th>strong_positive</th>\n",
              "      <th>strong_negative</th>\n",
              "      <th>strong_neutral</th>\n",
              "      <th>strong_both</th>\n",
              "      <th>weak_positive</th>\n",
              "      <th>weak_negative</th>\n",
              "      <th>weak_neutral</th>\n",
              "      <th>weak_both</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>222</td>\n",
              "      <td>5</td>\n",
              "      <td>The author generally stayed in one mood. The m...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[Offset 114, length 4, Rule ID: COMMA_COMPOUND...</td>\n",
              "      <td>9</td>\n",
              "      <td>The author generally stayed in one mood. The m...</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.011494</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045977</td>\n",
              "      <td>0.011494</td>\n",
              "      <td>0.022989</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11776dc0-d168-466e-942b-6befd2b3d37e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11776dc0-d168-466e-942b-6befd2b3d37e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11776dc0-d168-466e-942b-6befd2b3d37e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### kappa score\n"
      ],
      "metadata": {
        "id": "C4Lel7gvPtKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(df, topic, features, model):\n",
        "    \"\"\"Regression pipeline with kappa evaluation\"\"\"\n",
        "\n",
        "    X = df[df['topic'] == topic][features]\n",
        "    y = df[df['topic'] == topic]['target_score'].astype(np.float64)\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=26)\n",
        "    \n",
        "    model.fit(X_train, y_train)    \n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    return quadratic_weighted_kappa(y_pred, y_test)"
      ],
      "metadata": {
        "id": "kMaxVR-WLdWn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### funcs\n"
      ],
      "metadata": {
        "id": "CmedEn4CLiAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions taken From https://github.com/NishantSushmakar/Automated-Essay-Grading\n",
        "\n",
        "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
        "    \"\"\"\n",
        "    Returns the confusion matrix between rater's ratings\n",
        "    \"\"\"\n",
        "    assert(len(rater_a) == len(rater_b))\n",
        "    if min_rating is None:\n",
        "        min_rating = min(rater_a + rater_b)\n",
        "    if max_rating is None:\n",
        "        max_rating = max(rater_a + rater_b)\n",
        "    num_ratings = int(max_rating - min_rating + 1)\n",
        "    conf_mat = [[0 for i in range(num_ratings)]\n",
        "                for j in range(num_ratings)]\n",
        "    for a, b in zip(rater_a, rater_b):\n",
        "        conf_mat[a - min_rating][b - min_rating] += 1\n",
        "    return conf_mat\n",
        "\n",
        "\n",
        "def histogram(ratings, min_rating=None, max_rating=None):\n",
        "    \"\"\"\n",
        "    Returns the counts of each type of rating that a rater made\n",
        "    \"\"\"\n",
        "    if min_rating is None:\n",
        "        min_rating = min(ratings)\n",
        "    if max_rating is None:\n",
        "        max_rating = max(ratings)\n",
        "    num_ratings = int(max_rating - min_rating + 1)\n",
        "    hist_ratings = [0 for x in range(num_ratings)]\n",
        "    for r in ratings:\n",
        "        hist_ratings[r - min_rating] += 1\n",
        "    return hist_ratings\n",
        "\n",
        "def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n",
        "    \"\"\"\n",
        "    Calculates the quadratic weighted kappa\n",
        "    quadratic_weighted_kappa calculates the quadratic weighted kappa\n",
        "    value, which is a measure of inter-rater agreement between two raters\n",
        "    that provide discrete numeric ratings.  Potential values range from -1\n",
        "    (representing complete disagreement) to 1 (representing complete\n",
        "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
        "    chance.\n",
        "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
        "    each correspond to a list of integer ratings.  These lists must have the\n",
        "    same length.\n",
        "    The ratings should be integers, and it is assumed that they contain\n",
        "    the complete range of possible ratings.\n",
        "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
        "    is the minimum possible rating, and max_rating is the maximum possible\n",
        "    rating\n",
        "    \"\"\"\n",
        "    rater_a = np.array(rater_a, dtype=int)\n",
        "    rater_b = np.array(rater_b, dtype=int)\n",
        "    assert(len(rater_a) == len(rater_b))\n",
        "    if min_rating is None:\n",
        "        min_rating = min(min(rater_a), min(rater_b))\n",
        "    if max_rating is None:\n",
        "        max_rating = max(max(rater_a), max(rater_b))\n",
        "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
        "                                min_rating, max_rating)\n",
        "    num_ratings = len(conf_mat)\n",
        "    num_scored_items = float(len(rater_a))\n",
        "\n",
        "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
        "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
        "\n",
        "    numerator = 0.0\n",
        "    denominator = 0.0\n",
        "\n",
        "    for i in range(num_ratings):\n",
        "        for j in range(num_ratings):\n",
        "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
        "                              / num_scored_items)\n",
        "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
        "            numerator += d * conf_mat[i][j] / num_scored_items\n",
        "            denominator += d * expected_count / num_scored_items\n",
        "\n",
        "    return 1.0 - numerator / denominator\n",
        "\n"
      ],
      "metadata": {
        "id": "zYgKtmOHLj4X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model"
      ],
      "metadata": {
        "id": "g-GbUDbILokv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()"
      ],
      "metadata": {
        "id": "xVexXPTa2Edx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALL FEATURES KAPPA VALUES PER ESSAYSET\n",
        "essaysets = [1,3,4,5,6,7]\n",
        "\n",
        "kappas = []\n",
        "weights = []\n",
        "for essayset in essaysets:\n",
        "    kappas.append(evaluate(training_set, essayset, features, model))\n",
        "\n",
        "print(kappas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IwIw39pLtAs",
        "outputId": "df0e5a9f-b5ad-4b92-934e-316a1b5840b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8863109048723897, 0.45210727969348663, 0.3414634146341463, 0.5781710914454278, 0.46630727762803215, 0.5791027496382053]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langFeatures = ['word_count', 'sentence_count', 'unique_word_count' ]\n",
        "speechFeatures = ['noun', 'adj', 'pron', 'verb']\n",
        "orthoFeatures = ['corrections',  'misspelt']\n",
        "emotiveFeatures = ['strong_positive', 'strong_negative', 'strong_neutral', 'strong_both', 'weak_positive', 'weak_negative', 'weak_neutral', 'weak_both']\n",
        "\n"
      ],
      "metadata": {
        "id": "itDbmgq_uxLz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# SPECIFIC FEATURES KAPPA VALUES PER ESSAYSET\n",
        "# draw graph\n",
        "essaysets = [1,3,4,5,6,7]\n",
        "\n",
        "kappas1 = []\n",
        "kappas2 = []\n",
        "kappas3 = []\n",
        "kappas4 = []\n",
        "\n",
        "weights = []\n",
        "for essayset in essaysets:\n",
        "    kappas1.append(evaluate(training_set, essayset, langFeatures, model))\n",
        "    kappas2.append(evaluate(training_set, essayset, speechFeatures, model))\n",
        "    kappas3.append(evaluate(training_set, essayset, orthoFeatures, model))\n",
        "    kappas4.append(evaluate(training_set, essayset, emotiveFeatures, model))\n",
        "\n",
        "print('langFeatures', kappas1)\n",
        "print('partsofspeechFeatures', kappas2)\n",
        "print('orthoFeatures',kappas3)\n",
        "print('emotiveFeatures', kappas4)\n",
        "\n",
        "# languageFluency, PartsOfSpeech, Orthography, Subjective"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_hFhm-tviaM",
        "outputId": "da8f0e73-cc2f-4888-a06f-09fc3f9d9b6c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langFeatures [0.9006309148264984, 0.502262443438914, 0.5573440643863179, 0.5352112676056338, 0.21739130434782616, 0.6296326201049656]\n",
            "partsofspeechFeatures [0.8842105263157894, 0.502262443438914, 0.4488517745302716, 0.5352112676056339, 0.5652173913043479, 0.4925019731649566]\n",
            "orthoFeatures [-0.00517464424320857, 0.3390557939914163, 0.2256728778467908, 0.0, -0.029962546816479474, 0.38078164216565036]\n",
            "emotiveFeatures [-0.16666666666666652, -0.18326693227091595, 0.42105263157894735, 0.2978723404255319, 0.50561797752809, -0.09980738924881893]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = np.arange(6)\n",
        "y1 = kappas1\n",
        "y2 = kappas2\n",
        "y3 = kappas3\n",
        "y4 = kappas4\n",
        "width = 0.2\n",
        "  \n",
        "# plot data in grouped manner of bar type\n",
        "plt.bar(x-0.2, y1, width, color='blue')\n",
        "plt.bar(x, y2, width, color='orange')\n",
        "plt.bar(x+0.2, y3, width, color='lightgreen')\n",
        "plt.bar(x+0.2, y4, width, color='pink')\n",
        "plt.xticks(x, ['Set1', 'Set3', 'Set4', 'Set5', 'Set6', 'Set7'])\n",
        "\n",
        "plt.legend([\"LanguageFluency\", \"PartsOfSpeech\", \"Orthography\", \"Subjective\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xrtmdNL4JMNR",
        "outputId": "b65927f0-852d-4d83-fa9e-c4d38393fa41"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References: https://github.com/NishantSushmakar/Automated-Essay-Grading\n",
        "# https://www.statology.org/cohens-kappa-statistic/\n",
        "# http://www.kaggle.com/c/asap-aes"
      ],
      "metadata": {
        "id": "RxyRT-f-ulsA"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}